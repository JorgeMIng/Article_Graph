{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_ner import get_all_ners,get_all_projects\n",
    "from pdf_analyzer.config_load import load_config\n",
    "from pdf_analyzer.api import API\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"token-classification\", model=\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVER_CONFIG\n",
      "url:\n",
      "  protocol: http\n",
      "  api_domain: yordi111nas.synology.me\n",
      "  port: 8070\n",
      "\n",
      "CLOUD_CONFIG\n",
      "data:\n",
      "  data_dir: data/PDFs\n",
      "  format: .pdf\n",
      "  recursive: true\n",
      "grobid:\n",
      "  cache: true\n",
      "  cache_dir: data/xmls\n",
      "  operation_key: processFulltextDocument\n",
      "  format: .grobid.tei.xml\n",
      "  recursive: true\n",
      "\n",
      "http://yordi111nas.synology.me:8070/api/isalive\n",
      "GROBID server is up and running\n",
      "data/xmls\\nlp\\Bert.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\DistillBERT.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\Dont_stop_pretraining.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\GPT-3.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\LIME.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\LoRA.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\RoBERTa.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\SORA.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\Transformers.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "data/xmls\\nlp\\word2vec.grobid.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "grobid_logger: 2024-05-02 21:33:17,591 | INFO | API.py:44 | 4128 >>> All files have been process by the api\n"
     ]
    }
   ],
   "source": [
    "server_config = load_config(\"config/api/grobid-server-config.yaml\")\n",
    "extract_config = load_config(\"config/api/api-base-config.yaml\")\n",
    "print(\"SERVER_CONFIG\\n\"+OmegaConf.to_yaml(server_config))\n",
    "print(\"CLOUD_CONFIG\\n\"+OmegaConf.to_yaml(extract_config))\n",
    "\n",
    "base_api = API.BaseAPI(extract_config,server_config)\n",
    "\n",
    "files = base_api.proccesed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Al-lenNLP',\n",
       "  'score': 0.67498153,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 0,\n",
       "  'paper_id': 2},\n",
       " {'name': 'Office of Naval Research',\n",
       "  'score': 0.9967265,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 1,\n",
       "  'paper_id': 2},\n",
       " {'name': 'Google',\n",
       "  'score': 0.99887425,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 2,\n",
       "  'paper_id': 2},\n",
       " {'name': 'OpenAI',\n",
       "  'score': 0.9626693,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 3,\n",
       "  'paper_id': 3},\n",
       " {'name': 'WebText',\n",
       "  'score': 0.7112076,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 4,\n",
       "  'paper_id': 3},\n",
       " {'name': 'TerraSwarm',\n",
       "  'score': 0.99291795,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 5,\n",
       "  'paper_id': 4},\n",
       " {'name': 'STARnet',\n",
       "  'score': 0.87451035,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 6,\n",
       "  'paper_id': 4},\n",
       " {'name': 'Semiconductor Research Corporation',\n",
       "  'score': 0.9271019,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 7,\n",
       "  'paper_id': 4},\n",
       " {'name': 'MARCO',\n",
       "  'score': 0.9814992,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 8,\n",
       "  'paper_id': 4},\n",
       " {'name': 'DARPA',\n",
       "  'score': 0.976103,\n",
       "  'type': 'ORG',\n",
       "  'org_id': 9,\n",
       "  'paper_id': 4}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_orgs_rel,all_orgs=get_all_ners(files,pipe)\n",
    "all_orgs_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Al-lenNLP', 'type': 'ORG', 'org_id': 0},\n",
       " {'name': 'Office of Naval Research', 'type': 'ORG', 'org_id': 1},\n",
       " {'name': 'Google', 'type': 'ORG', 'org_id': 2},\n",
       " {'name': 'OpenAI', 'type': 'ORG', 'org_id': 3},\n",
       " {'name': 'WebText', 'type': 'ORG', 'org_id': 4},\n",
       " {'name': 'TerraSwarm', 'type': 'ORG', 'org_id': 5},\n",
       " {'name': 'STARnet', 'type': 'ORG', 'org_id': 6},\n",
       " {'name': 'Semiconductor Research Corporation', 'type': 'ORG', 'org_id': 7},\n",
       " {'name': 'MARCO', 'type': 'ORG', 'org_id': 8},\n",
       " {'name': 'DARPA', 'type': 'ORG', 'org_id': 9}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'project_name': 'MURI',\n",
       "  'project_federal_id': 'N00014-18-1-2670',\n",
       "  'project_id': 0},\n",
       " {'project_name': 'ONR',\n",
       "  'project_federal_id': '#N00014-13-1-0023',\n",
       "  'project_id': 1}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_projects,all_projects_relation=get_all_projects(files)\n",
    "all_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'project_name': 'MURI',\n",
       "  'project_federal_id': 'N00014-18-1-2670',\n",
       "  'project_id': 0,\n",
       "  'paper_id': 2},\n",
       " {'project_name': 'ONR',\n",
       "  'project_federal_id': '#N00014-13-1-0023',\n",
       "  'project_id': 1,\n",
       "  'paper_id': 4},\n",
       " {'project_name': 'ONR',\n",
       "  'project_federal_id': '#W911NF-13-1-0246',\n",
       "  'project_id': 1,\n",
       "  'paper_id': 4}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_projects_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_award_identifiers(text):\n",
    "    # Expresiones regulares para identificadores de premios\n",
    "    regex_patterns = {\n",
    "        \"NIH\": r'(?:#)?\\b[1-9][A-Z\\d]{3}[A-Z]{2}\\d{6}(?:-[AS]?\\d+)?\\b',\n",
    "        \"DOD\": r'(?:#)?\\b[A-Z\\d]{6}-\\d{2}-[123]-\\d{4}\\b',\n",
    "        \"NASA\": r'(?:#)?\\b(?:80|NN)[A-Z]+\\d{2}[A-Z\\d]+\\b',\n",
    "        \"Education\": r'(?:#)?\\b[A-Z]+\\d+[A-Z]\\d{2}[A-Z\\d]+\\b'\n",
    "    }\n",
    "\n",
    "    # Lista para almacenar todos los identificadores únicos encontrados\n",
    "    all_identifiers = []\n",
    "\n",
    "    # Aplicar cada expresión regular al texto y almacenar los resultados\n",
    "    for pattern in regex_patterns.values():\n",
    "        identifiers = re.findall(pattern, text)\n",
    "        all_identifiers.extend(identifiers)\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    unique_identifiers = list(set(all_identifiers))\n",
    "\n",
    "    return unique_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificadores de premios #2R01CA654321\n",
      "Identificadores de premios P031B201234\n",
      "Identificadores de premios #W912D1-21-3-9012\n",
      "Identificadores de premios W81XWH-22-1-1234\n",
      "Identificadores de premios #T042A190567\n",
      "Identificadores de premios 1R01CA123456\n",
      "Identificadores de premios NNC21AA02A\n",
      "Identificadores de premios NNC21AA01H\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "texto_ejemplo = \"\"\"\n",
    "Aquí hay algunos identificadores de premios:\n",
    "\n",
    "NIH: 1R01CA123456-01A1, #2R01CA654321-03B2\n",
    "DOD: W81XWH-22-1-1234, #W912D1-21-3-9012\n",
    "NASA: NNC21AA01H, #GRC20G-1234, NNC21AA02A\n",
    "Department of Education: P031B201234, #T042A190567\n",
    "\"\"\"\n",
    "\n",
    "# Extraer identificadores de premios del texto de ejemplo\n",
    "identificadores = extract_award_identifiers(texto_ejemplo)\n",
    "\n",
    "# Imprimir los identificadores encontrados para cada agencia\n",
    "for ids in identificadores:\n",
    "    print(f\"Identificadores de premios {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_identifiers_with_names(text):\n",
    "    # Obtener identificadores de premios del texto\n",
    "    identifiers = extract_award_identifiers(text)\n",
    "    \n",
    "    # Lista para almacenar nombres y códigos asociados\n",
    "    names_and_codes = []\n",
    "\n",
    "    # Iterar sobre los identificadores y buscar los nombres correspondientes\n",
    "    for identifier in identifiers:\n",
    "        # Buscar el nombre del proyecto antes del identificador\n",
    "        match = re.search(rf'(\\w+)\\s+(?:grant|award|code)\\s+{re.escape(identifier)}', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            names_and_codes.append((match.group(1), identifier))\n",
    "\n",
    "    return names_and_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projects_names(text):\n",
    "    # Obtener identificadores de premios del texto\n",
    "    identifiers = extract_award_identifiers(text)\n",
    "    \n",
    "    # Lista para almacenar nombres y códigos asociados\n",
    "    names_and_codes = []\n",
    "\n",
    "    # Iterar sobre los identificadores y buscar los nombres correspondientes\n",
    "    for identifier in identifiers:\n",
    "        # Buscar el nombre del proyecto antes del identificador\n",
    "        match = re.search(rf'(\\w+)\\s+(?:grant|award|code)\\s+{re.escape(identifier)}', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            names_and_codes.append(match.group(1))\n",
    "\n",
    "    return names_and_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DOD', 'Education', 'NASA', 'MURI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_ejemplo = \"\"\"\n",
    "Aquí hay algunos identificadores de premios con nombres asociados:\n",
    "\n",
    "MURI grant N00014-18-1-2670, MURI award N00014-18-1-2670\n",
    "DOD Award W81XWH-18-1-1234, Cooperative Agreement W911NF-20-2-5678\n",
    "NASA Grant NNC21AA01H, Research Cooperative Agreement GRC20G-1234, NNC21AA02A\n",
    "Department of Education Grant P031B201234, Grant T042A190567\n",
    "\"\"\"\n",
    "\n",
    "# Extraer nombres asociados con códigos del texto de ejemplo\n",
    "nombres_con_codigos = get_projects_names(texto_ejemplo)\n",
    "nombres_con_codigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DOD', 'Education', 'NASA', 'MURI']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres_con_codigos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
