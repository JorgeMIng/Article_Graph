{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to utilize different models to assess text similarity using the code from Model.py. Additionally, it provides explanations on how to utilize the code effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sentences will serve as input texts for the demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Ramona is a software engineer who loves coding.\",\n",
    "    \"Jorge enjoys reading books in his free time.\",\n",
    "    \"Marco sat with his cat under the tree. \",\n",
    "    \"The dog chased the monster in the park.\",\n",
    "    \"John and Mary went to the beach to fish for sharks.\",\n",
    "    \"Pizza is a common choice for food used to poison without detection. \",\n",
    "    \"The Mona Lisa is a famous painting by Leonardo da Vinci.\",\n",
    "    \"Mount Everest is the tallest mountain in the world.\",\n",
    "    \"The Great Wall of China is a UNESCO World Heritage Site.\",\n",
    "    \"Beethoven composed Symphony No. 9 in D minor.\",\n",
    "    \"The Earth revolves around the Sun.\",\n",
    "    \"Water boils at 100 degrees Celsius.\",\n",
    "    \"The capital of France is Paris.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access the code in similarity's folder\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "# pip install -U sentence-transformers\n",
    "from similarity.Model import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is particularly efficient in terms of size and computation. It uses MiniLM Architecture, a compact version of the BERT model based on the Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.0s aprox.\n",
    "# Name of the SentenceTransformer model to use\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# Create an instance of the class\n",
    "Model_instance = Model(sentences, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity results:\n",
      "{'text_id1': 0, 'text_id2': 1, 'similarity': 0.1597348}\n",
      "{'text_id1': 0, 'text_id2': 2, 'similarity': 0.0818415}\n",
      "{'text_id1': 0, 'text_id2': 3, 'similarity': 0.055600088}\n",
      "{'text_id1': 0, 'text_id2': 4, 'similarity': 0.14304014}\n",
      "{'text_id1': 0, 'text_id2': 5, 'similarity': 0.034660123}\n",
      "{'text_id1': 0, 'text_id2': 6, 'similarity': 0.046214547}\n",
      "{'text_id1': 0, 'text_id2': 7, 'similarity': 0.022117741}\n",
      "{'text_id1': 0, 'text_id2': 8, 'similarity': -0.037078083}\n",
      "{'text_id1': 0, 'text_id2': 9, 'similarity': 0.06534709}\n",
      "{'text_id1': 0, 'text_id2': 10, 'similarity': -0.035998903}\n",
      "{'text_id1': 0, 'text_id2': 11, 'similarity': -0.016028896}\n",
      "{'text_id1': 0, 'text_id2': 12, 'similarity': 0.022813598}\n",
      "{'text_id1': 1, 'text_id2': 2, 'similarity': 0.15311185}\n",
      "{'text_id1': 1, 'text_id2': 3, 'similarity': -0.07004532}\n",
      "{'text_id1': 1, 'text_id2': 4, 'similarity': 0.11294486}\n",
      "{'text_id1': 1, 'text_id2': 5, 'similarity': 0.018555606}\n",
      "{'text_id1': 1, 'text_id2': 6, 'similarity': 0.088100985}\n",
      "{'text_id1': 1, 'text_id2': 7, 'similarity': 0.0841396}\n",
      "{'text_id1': 1, 'text_id2': 8, 'similarity': -0.007191075}\n",
      "{'text_id1': 1, 'text_id2': 9, 'similarity': -0.0047434773}\n",
      "{'text_id1': 1, 'text_id2': 10, 'similarity': 0.05863238}\n",
      "{'text_id1': 1, 'text_id2': 11, 'similarity': 0.022922914}\n",
      "{'text_id1': 1, 'text_id2': 12, 'similarity': 0.054697633}\n",
      "{'text_id1': 2, 'text_id2': 3, 'similarity': 0.15434094}\n",
      "{'text_id1': 2, 'text_id2': 4, 'similarity': 0.17770915}\n",
      "{'text_id1': 2, 'text_id2': 5, 'similarity': 0.107857555}\n",
      "{'text_id1': 2, 'text_id2': 6, 'similarity': 0.054371502}\n",
      "{'text_id1': 2, 'text_id2': 7, 'similarity': 0.047930263}\n",
      "{'text_id1': 2, 'text_id2': 8, 'similarity': 0.052940253}\n",
      "{'text_id1': 2, 'text_id2': 9, 'similarity': 0.13017467}\n",
      "{'text_id1': 2, 'text_id2': 10, 'similarity': 0.13904312}\n",
      "{'text_id1': 2, 'text_id2': 11, 'similarity': -0.05909795}\n",
      "{'text_id1': 2, 'text_id2': 12, 'similarity': -0.015324969}\n",
      "{'text_id1': 3, 'text_id2': 4, 'similarity': 0.07193116}\n",
      "{'text_id1': 3, 'text_id2': 5, 'similarity': 0.08704511}\n",
      "{'text_id1': 3, 'text_id2': 6, 'similarity': 0.04798231}\n",
      "{'text_id1': 3, 'text_id2': 7, 'similarity': 0.02122672}\n",
      "{'text_id1': 3, 'text_id2': 8, 'similarity': 0.077485755}\n",
      "{'text_id1': 3, 'text_id2': 9, 'similarity': 0.113664486}\n",
      "{'text_id1': 3, 'text_id2': 10, 'similarity': 0.068835266}\n",
      "{'text_id1': 3, 'text_id2': 11, 'similarity': -0.029480426}\n",
      "{'text_id1': 3, 'text_id2': 12, 'similarity': -0.06172352}\n",
      "{'text_id1': 4, 'text_id2': 5, 'similarity': 0.14593674}\n",
      "{'text_id1': 4, 'text_id2': 6, 'similarity': 0.1601226}\n",
      "{'text_id1': 4, 'text_id2': 7, 'similarity': -0.035022408}\n",
      "{'text_id1': 4, 'text_id2': 8, 'similarity': -0.077518746}\n",
      "{'text_id1': 4, 'text_id2': 9, 'similarity': -0.041810483}\n",
      "{'text_id1': 4, 'text_id2': 10, 'similarity': 0.058826767}\n",
      "{'text_id1': 4, 'text_id2': 11, 'similarity': 0.0031435192}\n",
      "{'text_id1': 4, 'text_id2': 12, 'similarity': -0.010622593}\n",
      "{'text_id1': 5, 'text_id2': 6, 'similarity': 0.073784985}\n",
      "{'text_id1': 5, 'text_id2': 7, 'similarity': 0.016650226}\n",
      "{'text_id1': 5, 'text_id2': 8, 'similarity': 0.0036922991}\n",
      "{'text_id1': 5, 'text_id2': 9, 'similarity': 0.047769725}\n",
      "{'text_id1': 5, 'text_id2': 10, 'similarity': -0.00082287565}\n",
      "{'text_id1': 5, 'text_id2': 11, 'similarity': 0.041777812}\n",
      "{'text_id1': 5, 'text_id2': 12, 'similarity': 0.11072664}\n",
      "{'text_id1': 6, 'text_id2': 7, 'similarity': 0.21788013}\n",
      "{'text_id1': 6, 'text_id2': 8, 'similarity': 0.24117988}\n",
      "{'text_id1': 6, 'text_id2': 9, 'similarity': 0.037812494}\n",
      "{'text_id1': 6, 'text_id2': 10, 'similarity': 0.14030084}\n",
      "{'text_id1': 6, 'text_id2': 11, 'similarity': 0.0845358}\n",
      "{'text_id1': 6, 'text_id2': 12, 'similarity': 0.17287454}\n",
      "{'text_id1': 7, 'text_id2': 8, 'similarity': 0.26428252}\n",
      "{'text_id1': 7, 'text_id2': 9, 'similarity': 0.015317418}\n",
      "{'text_id1': 7, 'text_id2': 10, 'similarity': 0.108245656}\n",
      "{'text_id1': 7, 'text_id2': 11, 'similarity': 0.05377059}\n",
      "{'text_id1': 7, 'text_id2': 12, 'similarity': 0.06731422}\n",
      "{'text_id1': 8, 'text_id2': 9, 'similarity': 0.04191026}\n",
      "{'text_id1': 8, 'text_id2': 10, 'similarity': 0.068718225}\n",
      "{'text_id1': 8, 'text_id2': 11, 'similarity': 0.003577061}\n",
      "{'text_id1': 8, 'text_id2': 12, 'similarity': 0.14937645}\n",
      "{'text_id1': 9, 'text_id2': 10, 'similarity': 0.032985415}\n",
      "{'text_id1': 9, 'text_id2': 11, 'similarity': 0.00032598153}\n",
      "{'text_id1': 9, 'text_id2': 12, 'similarity': 0.072586976}\n",
      "{'text_id1': 10, 'text_id2': 11, 'similarity': 0.12824222}\n",
      "{'text_id1': 10, 'text_id2': 12, 'similarity': 0.115137935}\n",
      "{'text_id1': 11, 'text_id2': 12, 'similarity': 0.15222162}\n"
     ]
    }
   ],
   "source": [
    "# 10s aprox.\n",
    "# Calculate and display similarity between the texts; 2.8 seg aprox.\n",
    "Model_instance.calculate_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between all-MiniLM-L6-v2 and MiniLM-L12-v2 is the number of layers (L6 = 6; L12 = 12), which affects the size, performance, and computational requirements. Furthermore, paraphrase-multilingual-MiniLM-L12-v2 is specifically tailored for paraphrase detection and semantic similarity tasks, while all-MiniLM-L6-v2 is a general purpose model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24.3s aprox\n",
    "# Name of the SentenceTransformer model to use\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "# Create an instance of the class\n",
    "Model_instance = Model(sentences, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity results:\n",
      "{'text_id1': 0, 'text_id2': 1, 'similarity': 0.20741831}\n",
      "{'text_id1': 0, 'text_id2': 2, 'similarity': 0.22545972}\n",
      "{'text_id1': 0, 'text_id2': 3, 'similarity': -0.034786206}\n",
      "{'text_id1': 0, 'text_id2': 4, 'similarity': -0.041520074}\n",
      "{'text_id1': 0, 'text_id2': 5, 'similarity': 0.10810112}\n",
      "{'text_id1': 0, 'text_id2': 6, 'similarity': -0.13943337}\n",
      "{'text_id1': 0, 'text_id2': 7, 'similarity': -0.07726742}\n",
      "{'text_id1': 0, 'text_id2': 8, 'similarity': -0.08653814}\n",
      "{'text_id1': 0, 'text_id2': 9, 'similarity': 0.16482522}\n",
      "{'text_id1': 0, 'text_id2': 10, 'similarity': -0.023441505}\n",
      "{'text_id1': 0, 'text_id2': 11, 'similarity': -0.089713834}\n",
      "{'text_id1': 0, 'text_id2': 12, 'similarity': -0.18638453}\n",
      "{'text_id1': 1, 'text_id2': 2, 'similarity': 0.2598317}\n",
      "{'text_id1': 1, 'text_id2': 3, 'similarity': -0.12257454}\n",
      "{'text_id1': 1, 'text_id2': 4, 'similarity': -0.10347988}\n",
      "{'text_id1': 1, 'text_id2': 5, 'similarity': 0.07109052}\n",
      "{'text_id1': 1, 'text_id2': 6, 'similarity': 0.10536748}\n",
      "{'text_id1': 1, 'text_id2': 7, 'similarity': -0.0029914957}\n",
      "{'text_id1': 1, 'text_id2': 8, 'similarity': 0.018725652}\n",
      "{'text_id1': 1, 'text_id2': 9, 'similarity': 0.13687518}\n",
      "{'text_id1': 1, 'text_id2': 10, 'similarity': 0.06117145}\n",
      "{'text_id1': 1, 'text_id2': 11, 'similarity': 0.017378988}\n",
      "{'text_id1': 1, 'text_id2': 12, 'similarity': 0.061858397}\n",
      "{'text_id1': 2, 'text_id2': 3, 'similarity': 0.019551065}\n",
      "{'text_id1': 2, 'text_id2': 4, 'similarity': -0.020054333}\n",
      "{'text_id1': 2, 'text_id2': 5, 'similarity': 0.099614605}\n",
      "{'text_id1': 2, 'text_id2': 6, 'similarity': -0.07216206}\n",
      "{'text_id1': 2, 'text_id2': 7, 'similarity': -0.132617}\n",
      "{'text_id1': 2, 'text_id2': 8, 'similarity': -0.010896467}\n",
      "{'text_id1': 2, 'text_id2': 9, 'similarity': 0.1917642}\n",
      "{'text_id1': 2, 'text_id2': 10, 'similarity': 0.07590391}\n",
      "{'text_id1': 2, 'text_id2': 11, 'similarity': -0.0886413}\n",
      "{'text_id1': 2, 'text_id2': 12, 'similarity': -0.050062418}\n",
      "{'text_id1': 3, 'text_id2': 4, 'similarity': -0.01357322}\n",
      "{'text_id1': 3, 'text_id2': 5, 'similarity': 0.07800208}\n",
      "{'text_id1': 3, 'text_id2': 6, 'similarity': 0.20975217}\n",
      "{'text_id1': 3, 'text_id2': 7, 'similarity': 0.14514841}\n",
      "{'text_id1': 3, 'text_id2': 8, 'similarity': 0.13471302}\n",
      "{'text_id1': 3, 'text_id2': 9, 'similarity': 0.18923554}\n",
      "{'text_id1': 3, 'text_id2': 10, 'similarity': 0.054458868}\n",
      "{'text_id1': 3, 'text_id2': 11, 'similarity': -0.060380965}\n",
      "{'text_id1': 3, 'text_id2': 12, 'similarity': 0.123347715}\n",
      "{'text_id1': 4, 'text_id2': 5, 'similarity': 0.08163662}\n",
      "{'text_id1': 4, 'text_id2': 6, 'similarity': 0.17143992}\n",
      "{'text_id1': 4, 'text_id2': 7, 'similarity': 0.015538836}\n",
      "{'text_id1': 4, 'text_id2': 8, 'similarity': 0.032407552}\n",
      "{'text_id1': 4, 'text_id2': 9, 'similarity': -0.1444555}\n",
      "{'text_id1': 4, 'text_id2': 10, 'similarity': 0.03936144}\n",
      "{'text_id1': 4, 'text_id2': 11, 'similarity': 0.059242357}\n",
      "{'text_id1': 4, 'text_id2': 12, 'similarity': 0.03381838}\n",
      "{'text_id1': 5, 'text_id2': 6, 'similarity': -0.026646845}\n",
      "{'text_id1': 5, 'text_id2': 7, 'similarity': 0.0054073706}\n",
      "{'text_id1': 5, 'text_id2': 8, 'similarity': 0.034363896}\n",
      "{'text_id1': 5, 'text_id2': 9, 'similarity': 0.06680418}\n",
      "{'text_id1': 5, 'text_id2': 10, 'similarity': 0.027052535}\n",
      "{'text_id1': 5, 'text_id2': 11, 'similarity': 0.03223912}\n",
      "{'text_id1': 5, 'text_id2': 12, 'similarity': 0.2165367}\n",
      "{'text_id1': 6, 'text_id2': 7, 'similarity': 0.11646256}\n",
      "{'text_id1': 6, 'text_id2': 8, 'similarity': 0.24785191}\n",
      "{'text_id1': 6, 'text_id2': 9, 'similarity': 0.09713261}\n",
      "{'text_id1': 6, 'text_id2': 10, 'similarity': 0.2193695}\n",
      "{'text_id1': 6, 'text_id2': 11, 'similarity': 0.09818354}\n",
      "{'text_id1': 6, 'text_id2': 12, 'similarity': 0.30212194}\n",
      "{'text_id1': 7, 'text_id2': 8, 'similarity': 0.3112116}\n",
      "{'text_id1': 7, 'text_id2': 9, 'similarity': -0.010020945}\n",
      "{'text_id1': 7, 'text_id2': 10, 'similarity': 0.14062193}\n",
      "{'text_id1': 7, 'text_id2': 11, 'similarity': 0.06303139}\n",
      "{'text_id1': 7, 'text_id2': 12, 'similarity': 0.06842351}\n",
      "{'text_id1': 8, 'text_id2': 9, 'similarity': 0.019166965}\n",
      "{'text_id1': 8, 'text_id2': 10, 'similarity': 0.1623507}\n",
      "{'text_id1': 8, 'text_id2': 11, 'similarity': 0.055282984}\n",
      "{'text_id1': 8, 'text_id2': 12, 'similarity': 0.15896502}\n",
      "{'text_id1': 9, 'text_id2': 10, 'similarity': 0.010732405}\n",
      "{'text_id1': 9, 'text_id2': 11, 'similarity': 0.060062617}\n",
      "{'text_id1': 9, 'text_id2': 12, 'similarity': 0.09474179}\n",
      "{'text_id1': 10, 'text_id2': 11, 'similarity': 0.064579345}\n",
      "{'text_id1': 10, 'text_id2': 12, 'similarity': 0.17291775}\n",
      "{'text_id1': 11, 'text_id2': 12, 'similarity': 0.04601758}\n"
     ]
    }
   ],
   "source": [
    "# 0.6s aprox.\n",
    "# Calculate and display similarity between the texts\n",
    "Model_instance.calculate_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPNet (Mobileformer) model, a transformer-based model developed by Microsoft Research. It usually works best when you need fast responses, privacy, or computing close to the data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.5s aprox --> best one\n",
    "# Name of the SentenceTransformer model to use\n",
    "model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "# Create an instance of the class\n",
    "Model_instance = Model(sentences, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity results:\n",
      "{'text_id1': 0, 'text_id2': 1, 'similarity': 0.20646062}\n",
      "{'text_id1': 0, 'text_id2': 2, 'similarity': -0.0046621906}\n",
      "{'text_id1': 0, 'text_id2': 3, 'similarity': -0.08455665}\n",
      "{'text_id1': 0, 'text_id2': 4, 'similarity': 0.017528454}\n",
      "{'text_id1': 0, 'text_id2': 5, 'similarity': 0.1032789}\n",
      "{'text_id1': 0, 'text_id2': 6, 'similarity': 0.13802837}\n",
      "{'text_id1': 0, 'text_id2': 7, 'similarity': -0.0075252354}\n",
      "{'text_id1': 0, 'text_id2': 8, 'similarity': 0.017472018}\n",
      "{'text_id1': 0, 'text_id2': 9, 'similarity': -0.032865025}\n",
      "{'text_id1': 0, 'text_id2': 10, 'similarity': 0.033637233}\n",
      "{'text_id1': 0, 'text_id2': 11, 'similarity': -0.020414997}\n",
      "{'text_id1': 0, 'text_id2': 12, 'similarity': 0.033197947}\n",
      "{'text_id1': 1, 'text_id2': 2, 'similarity': 0.0645885}\n",
      "{'text_id1': 1, 'text_id2': 3, 'similarity': -0.010923749}\n",
      "{'text_id1': 1, 'text_id2': 4, 'similarity': 0.08825572}\n",
      "{'text_id1': 1, 'text_id2': 5, 'similarity': 0.02201602}\n",
      "{'text_id1': 1, 'text_id2': 6, 'similarity': 0.12822753}\n",
      "{'text_id1': 1, 'text_id2': 7, 'similarity': 0.051447015}\n",
      "{'text_id1': 1, 'text_id2': 8, 'similarity': 0.05080925}\n",
      "{'text_id1': 1, 'text_id2': 9, 'similarity': 0.1170894}\n",
      "{'text_id1': 1, 'text_id2': 10, 'similarity': 0.08292469}\n",
      "{'text_id1': 1, 'text_id2': 11, 'similarity': -0.04121085}\n",
      "{'text_id1': 1, 'text_id2': 12, 'similarity': 0.057256434}\n",
      "{'text_id1': 2, 'text_id2': 3, 'similarity': 0.12377599}\n",
      "{'text_id1': 2, 'text_id2': 4, 'similarity': 0.09644707}\n",
      "{'text_id1': 2, 'text_id2': 5, 'similarity': 0.100969896}\n",
      "{'text_id1': 2, 'text_id2': 6, 'similarity': 0.002329776}\n",
      "{'text_id1': 2, 'text_id2': 7, 'similarity': 0.011075565}\n",
      "{'text_id1': 2, 'text_id2': 8, 'similarity': -0.08548164}\n",
      "{'text_id1': 2, 'text_id2': 9, 'similarity': 0.09430868}\n",
      "{'text_id1': 2, 'text_id2': 10, 'similarity': 0.069562145}\n",
      "{'text_id1': 2, 'text_id2': 11, 'similarity': 0.08835048}\n",
      "{'text_id1': 2, 'text_id2': 12, 'similarity': -0.029403074}\n",
      "{'text_id1': 3, 'text_id2': 4, 'similarity': 0.07956308}\n",
      "{'text_id1': 3, 'text_id2': 5, 'similarity': 0.061542258}\n",
      "{'text_id1': 3, 'text_id2': 6, 'similarity': 0.05979617}\n",
      "{'text_id1': 3, 'text_id2': 7, 'similarity': 0.056871388}\n",
      "{'text_id1': 3, 'text_id2': 8, 'similarity': 0.007088907}\n",
      "{'text_id1': 3, 'text_id2': 9, 'similarity': 0.002527235}\n",
      "{'text_id1': 3, 'text_id2': 10, 'similarity': -0.009000871}\n",
      "{'text_id1': 3, 'text_id2': 11, 'similarity': 0.05143373}\n",
      "{'text_id1': 3, 'text_id2': 12, 'similarity': 0.03431932}\n",
      "{'text_id1': 4, 'text_id2': 5, 'similarity': 0.095312856}\n",
      "{'text_id1': 4, 'text_id2': 6, 'similarity': 0.12015633}\n",
      "{'text_id1': 4, 'text_id2': 7, 'similarity': -0.057493348}\n",
      "{'text_id1': 4, 'text_id2': 8, 'similarity': -0.055590358}\n",
      "{'text_id1': 4, 'text_id2': 9, 'similarity': 0.0042265356}\n",
      "{'text_id1': 4, 'text_id2': 10, 'similarity': 0.05861812}\n",
      "{'text_id1': 4, 'text_id2': 11, 'similarity': -0.029854916}\n",
      "{'text_id1': 4, 'text_id2': 12, 'similarity': -0.034208704}\n",
      "{'text_id1': 5, 'text_id2': 6, 'similarity': 0.048272856}\n",
      "{'text_id1': 5, 'text_id2': 7, 'similarity': 0.040722907}\n",
      "{'text_id1': 5, 'text_id2': 8, 'similarity': 0.003911934}\n",
      "{'text_id1': 5, 'text_id2': 9, 'similarity': -0.0155617455}\n",
      "{'text_id1': 5, 'text_id2': 10, 'similarity': -0.018883338}\n",
      "{'text_id1': 5, 'text_id2': 11, 'similarity': 0.12887648}\n",
      "{'text_id1': 5, 'text_id2': 12, 'similarity': 0.01026213}\n",
      "{'text_id1': 6, 'text_id2': 7, 'similarity': 0.17883484}\n",
      "{'text_id1': 6, 'text_id2': 8, 'similarity': 0.33954212}\n",
      "{'text_id1': 6, 'text_id2': 9, 'similarity': 0.19059668}\n",
      "{'text_id1': 6, 'text_id2': 10, 'similarity': 0.12967736}\n",
      "{'text_id1': 6, 'text_id2': 11, 'similarity': -0.01779655}\n",
      "{'text_id1': 6, 'text_id2': 12, 'similarity': 0.17618878}\n",
      "{'text_id1': 7, 'text_id2': 8, 'similarity': 0.33412382}\n",
      "{'text_id1': 7, 'text_id2': 9, 'similarity': 0.14990193}\n",
      "{'text_id1': 7, 'text_id2': 10, 'similarity': 0.18996088}\n",
      "{'text_id1': 7, 'text_id2': 11, 'similarity': 0.16682369}\n",
      "{'text_id1': 7, 'text_id2': 12, 'similarity': 0.16321865}\n",
      "{'text_id1': 8, 'text_id2': 9, 'similarity': 0.09537242}\n",
      "{'text_id1': 8, 'text_id2': 10, 'similarity': 0.082358725}\n",
      "{'text_id1': 8, 'text_id2': 11, 'similarity': 0.05716176}\n",
      "{'text_id1': 8, 'text_id2': 12, 'similarity': 0.25074154}\n",
      "{'text_id1': 9, 'text_id2': 10, 'similarity': 0.10876477}\n",
      "{'text_id1': 9, 'text_id2': 11, 'similarity': 0.039304845}\n",
      "{'text_id1': 9, 'text_id2': 12, 'similarity': 0.16183737}\n",
      "{'text_id1': 10, 'text_id2': 11, 'similarity': 0.09072005}\n",
      "{'text_id1': 10, 'text_id2': 12, 'similarity': 0.14149746}\n",
      "{'text_id1': 11, 'text_id2': 12, 'similarity': 0.0707672}\n"
     ]
    }
   ],
   "source": [
    "# 0.9s aprox.\n",
    "# Calculate and display similarity between the texts\n",
    "Model_instance.calculate_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paraphrase-multilingual-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paraphrase-multilingual-mpnet-base-v2 is specifically tailored for paraphrase detection and semantic similarity tasks, while all-mpnet-base-v2 is a general purpose model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3m 4.2s aprox.\n",
    "# Name of the SentenceTransformer model to use\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
    "\n",
    "# Create an instance of the class\n",
    "Model_instance = Model(sentences, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity results:\n",
      "{'text_id1': 0, 'text_id2': 1, 'similarity': 0.30339304}\n",
      "{'text_id1': 0, 'text_id2': 2, 'similarity': 0.089907266}\n",
      "{'text_id1': 0, 'text_id2': 3, 'similarity': -0.011231708}\n",
      "{'text_id1': 0, 'text_id2': 4, 'similarity': 0.014406752}\n",
      "{'text_id1': 0, 'text_id2': 5, 'similarity': 0.07260013}\n",
      "{'text_id1': 0, 'text_id2': 6, 'similarity': 0.20138864}\n",
      "{'text_id1': 0, 'text_id2': 7, 'similarity': -0.015593786}\n",
      "{'text_id1': 0, 'text_id2': 8, 'similarity': 0.012397654}\n",
      "{'text_id1': 0, 'text_id2': 9, 'similarity': 0.024085607}\n",
      "{'text_id1': 0, 'text_id2': 10, 'similarity': 0.005255349}\n",
      "{'text_id1': 0, 'text_id2': 11, 'similarity': 0.030095711}\n",
      "{'text_id1': 0, 'text_id2': 12, 'similarity': 0.031220898}\n",
      "{'text_id1': 1, 'text_id2': 2, 'similarity': 0.26790628}\n",
      "{'text_id1': 1, 'text_id2': 3, 'similarity': 0.014833647}\n",
      "{'text_id1': 1, 'text_id2': 4, 'similarity': 0.028790228}\n",
      "{'text_id1': 1, 'text_id2': 5, 'similarity': 0.07778351}\n",
      "{'text_id1': 1, 'text_id2': 6, 'similarity': 0.06813321}\n",
      "{'text_id1': 1, 'text_id2': 7, 'similarity': 0.0065455344}\n",
      "{'text_id1': 1, 'text_id2': 8, 'similarity': -0.004513465}\n",
      "{'text_id1': 1, 'text_id2': 9, 'similarity': 0.13805024}\n",
      "{'text_id1': 1, 'text_id2': 10, 'similarity': 0.13592571}\n",
      "{'text_id1': 1, 'text_id2': 11, 'similarity': 0.011363876}\n",
      "{'text_id1': 1, 'text_id2': 12, 'similarity': 0.006765764}\n",
      "{'text_id1': 2, 'text_id2': 3, 'similarity': 0.14240529}\n",
      "{'text_id1': 2, 'text_id2': 4, 'similarity': 0.10663284}\n",
      "{'text_id1': 2, 'text_id2': 5, 'similarity': 0.15442613}\n",
      "{'text_id1': 2, 'text_id2': 6, 'similarity': 0.13454199}\n",
      "{'text_id1': 2, 'text_id2': 7, 'similarity': 0.019379135}\n",
      "{'text_id1': 2, 'text_id2': 8, 'similarity': 0.04333291}\n",
      "{'text_id1': 2, 'text_id2': 9, 'similarity': 0.11739918}\n",
      "{'text_id1': 2, 'text_id2': 10, 'similarity': 0.09359475}\n",
      "{'text_id1': 2, 'text_id2': 11, 'similarity': 0.012688097}\n",
      "{'text_id1': 2, 'text_id2': 12, 'similarity': -0.0012148414}\n",
      "{'text_id1': 3, 'text_id2': 4, 'similarity': 0.1115603}\n",
      "{'text_id1': 3, 'text_id2': 5, 'similarity': 0.007557891}\n",
      "{'text_id1': 3, 'text_id2': 6, 'similarity': 0.09639402}\n",
      "{'text_id1': 3, 'text_id2': 7, 'similarity': 0.0324746}\n",
      "{'text_id1': 3, 'text_id2': 8, 'similarity': 0.047920637}\n",
      "{'text_id1': 3, 'text_id2': 9, 'similarity': -0.060049526}\n",
      "{'text_id1': 3, 'text_id2': 10, 'similarity': 0.028200898}\n",
      "{'text_id1': 3, 'text_id2': 11, 'similarity': -0.02427559}\n",
      "{'text_id1': 3, 'text_id2': 12, 'similarity': -0.040831532}\n",
      "{'text_id1': 4, 'text_id2': 5, 'similarity': 0.13226533}\n",
      "{'text_id1': 4, 'text_id2': 6, 'similarity': 0.07152335}\n",
      "{'text_id1': 4, 'text_id2': 7, 'similarity': -0.09561447}\n",
      "{'text_id1': 4, 'text_id2': 8, 'similarity': -0.11107038}\n",
      "{'text_id1': 4, 'text_id2': 9, 'similarity': -0.102422945}\n",
      "{'text_id1': 4, 'text_id2': 10, 'similarity': -0.026979245}\n",
      "{'text_id1': 4, 'text_id2': 11, 'similarity': -0.06411146}\n",
      "{'text_id1': 4, 'text_id2': 12, 'similarity': -0.08612508}\n",
      "{'text_id1': 5, 'text_id2': 6, 'similarity': 0.035270788}\n",
      "{'text_id1': 5, 'text_id2': 7, 'similarity': -0.025364732}\n",
      "{'text_id1': 5, 'text_id2': 8, 'similarity': 0.021073066}\n",
      "{'text_id1': 5, 'text_id2': 9, 'similarity': -0.115428284}\n",
      "{'text_id1': 5, 'text_id2': 10, 'similarity': 0.045485638}\n",
      "{'text_id1': 5, 'text_id2': 11, 'similarity': 0.13084745}\n",
      "{'text_id1': 5, 'text_id2': 12, 'similarity': -0.027783187}\n",
      "{'text_id1': 6, 'text_id2': 7, 'similarity': 0.05526444}\n",
      "{'text_id1': 6, 'text_id2': 8, 'similarity': 0.28816202}\n",
      "{'text_id1': 6, 'text_id2': 9, 'similarity': 0.16194728}\n",
      "{'text_id1': 6, 'text_id2': 10, 'similarity': 0.14476672}\n",
      "{'text_id1': 6, 'text_id2': 11, 'similarity': -0.05277271}\n",
      "{'text_id1': 6, 'text_id2': 12, 'similarity': 0.19868389}\n",
      "{'text_id1': 7, 'text_id2': 8, 'similarity': 0.33522457}\n",
      "{'text_id1': 7, 'text_id2': 9, 'similarity': -0.018648246}\n",
      "{'text_id1': 7, 'text_id2': 10, 'similarity': 0.1992378}\n",
      "{'text_id1': 7, 'text_id2': 11, 'similarity': 0.07148215}\n",
      "{'text_id1': 7, 'text_id2': 12, 'similarity': 0.21033259}\n",
      "{'text_id1': 8, 'text_id2': 9, 'similarity': 0.046573795}\n",
      "{'text_id1': 8, 'text_id2': 10, 'similarity': 0.12690124}\n",
      "{'text_id1': 8, 'text_id2': 11, 'similarity': 0.113263674}\n",
      "{'text_id1': 8, 'text_id2': 12, 'similarity': 0.30141807}\n",
      "{'text_id1': 9, 'text_id2': 10, 'similarity': 0.031430453}\n",
      "{'text_id1': 9, 'text_id2': 11, 'similarity': -0.027493453}\n",
      "{'text_id1': 9, 'text_id2': 12, 'similarity': 0.07610318}\n",
      "{'text_id1': 10, 'text_id2': 11, 'similarity': 0.13198863}\n",
      "{'text_id1': 10, 'text_id2': 12, 'similarity': 0.024658002}\n",
      "{'text_id1': 11, 'text_id2': 12, 'similarity': -0.039826088}\n"
     ]
    }
   ],
   "source": [
    "# 1.4s\n",
    "# Calculate and display similarity between the texts\n",
    "Model_instance.calculate_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaBSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaBSE specializes in creating embeddings that are effective across various languages for cross-lingual tasks (Language-agnostic BERT Sentence Embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 1883.73 MB. The target location C:\\Users\\Gloria\\.cache\\huggingface\\hub only has 0.20 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 1883.73 MB. The target location C:\\Users\\Gloria\\.cache\\huggingface\\hub\\models--sentence-transformers--LaBSE\\blobs only has 0.20 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/LaBSE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create an instance of the class\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m Model_instance \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\Article_Graph\\similarity\\Model.py:18\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, texts, model_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;241m=\u001b[39m texts\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize the SentenceTransformer model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:197\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[0;32m    194\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(model_name_or_path, token, cache_folder\u001b[38;5;241m=\u001b[39mcache_folder, revision\u001b[38;5;241m=\u001b[39mrevision):\n\u001b[1;32m--> 197\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    206\u001b[0m         model_name_or_path,\n\u001b[0;32m    207\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    211\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1296\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1295\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_args\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hub_kwargs\n\u001b[1;32m-> 1296\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;66;03m# Normalize does not require any files to be loaded\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_class \u001b[38;5;241m==\u001b[39m Normalize:\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:36\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[0;32m     35\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     39\u001b[0m     tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path,\n\u001b[0;32m     40\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args,\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:65\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir, **model_args)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:3306\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3291\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   3292\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[0;32m   3294\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[0;32m   3305\u001b[0m     }\n\u001b[1;32m-> 3306\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3308\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   3310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[0;32m   3311\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    413\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1492\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1489\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1490\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[1;32m-> 1492\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1503\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:538\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    537\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[1;32m--> 538\u001b[0m     \u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m     new_resume_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;66;03m# Some data has been downloaded from the server so we reset the number of retries.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tempfile.py:499\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;129m@_functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# 30s aprox.\n",
    "# Name of the SentenceTransformer model to use\n",
    "model_name = 'sentence-transformers/LaBSE'\n",
    "\n",
    "# Create an instance of the class\n",
    "Model_instance = Model(sentences, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1s aprox.\n",
    "# Calculate and display similarity between the texts\n",
    "Model_instance.calculate_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilUSE (distiluse-base-multilingual-cased-v2) is tailored for generating multilingual sentence embeddings primarily for tasks like sentence similarity and semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.00 MB. The target location C:\\Users\\Gloria\\.cache\\huggingface\\hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.00 MB. The target location C:\\Users\\Gloria\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased-v2\\blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "No sentence-transformers model found with name sentence-transformers/distiluse-base-multilingual-cased-v2. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado: 'C:\\\\Users\\\\Gloria\\\\.cache\\\\huggingface\\\\hub\\\\models--sentence-transformers--distiluse-base-multilingual-cased-v2\\\\tmp_ff3f586f-5cab-4ad4-8343-b01194fe9acb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1722\u001b[0m, in \u001b[0;36m_chmod_and_replace\u001b[1;34m(src, dst)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1722\u001b[0m     \u001b[43mtmp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtouch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1723\u001b[0m     cache_dir_mode \u001b[38;5;241m=\u001b[39m Path(tmp_file)\u001b[38;5;241m.\u001b[39mstat()\u001b[38;5;241m.\u001b[39mst_mode\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1303\u001b[0m, in \u001b[0;36mPath.touch\u001b[1;34m(self, mode, exist_ok)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mO_EXCL\n\u001b[1;32m-> 1303\u001b[0m fd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1304\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(fd)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device: 'C:\\\\Users\\\\Gloria\\\\.cache\\\\huggingface\\\\hub\\\\models--sentence-transformers--distiluse-base-multilingual-cased-v2\\\\tmp_ff3f586f-5cab-4ad4-8343-b01194fe9acb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/distiluse-base-multilingual-cased-v2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create an instance of the class\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m Model_instance \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\Article_Graph\\similarity\\Model.py:18\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, texts, model_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;241m=\u001b[39m texts\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize the SentenceTransformer model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:205\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[0;32m    197\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(\n\u001b[0;32m    198\u001b[0m             model_name_or_path,\n\u001b[0;32m    199\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m             trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    203\u001b[0m         )\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_auto_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[0;32m    214\u001b[0m     modules \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1197\u001b[0m, in \u001b[0;36mSentenceTransformer._load_auto_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03mCreates a simple Transformer + Mean Pooling model and returns the modules\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sentence-transformers model found with name \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Creating a new one with MEAN pooling.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1194\u001b[0m         model_name_or_path\n\u001b[0;32m   1195\u001b[0m     )\n\u001b[0;32m   1196\u001b[0m )\n\u001b[1;32m-> 1197\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrust_remote_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrevision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrust_remote_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrevision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1203\u001b[0m pooling_model \u001b[38;5;241m=\u001b[39m Pooling(transformer_model\u001b[38;5;241m.\u001b[39mget_word_embedding_dimension(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [transformer_model, pooling_model]\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:35\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_seq_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_lower_case\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[1;32m---> 35\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     39\u001b[0m     tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path,\n\u001b[0;32m     40\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:928\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    926\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 928\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    929\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    930\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\configuration_utils.py:686\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    413\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1504\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1503\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1504\u001b[0m     \u001b[43m_chmod_and_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1505\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1726\u001b[0m, in \u001b[0;36m_chmod_and_replace\u001b[1;34m(src, dst)\u001b[0m\n\u001b[0;32m   1724\u001b[0m     os\u001b[38;5;241m.\u001b[39mchmod(src, stat\u001b[38;5;241m.\u001b[39mS_IMODE(cache_dir_mode))\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m-> 1726\u001b[0m     \u001b[43mtmp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1728\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmove(src, dst)\n",
      "File \u001b[1;32mc:\\Users\\Gloria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1342\u001b[0m, in \u001b[0;36mPath.unlink\u001b[1;34m(self, missing_ok)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03mRemove this file or link.\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1342\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado: 'C:\\\\Users\\\\Gloria\\\\.cache\\\\huggingface\\\\hub\\\\models--sentence-transformers--distiluse-base-multilingual-cased-v2\\\\tmp_ff3f586f-5cab-4ad4-8343-b01194fe9acb'"
     ]
    }
   ],
   "source": [
    "# 15s aprox.\n",
    "# Name of the SentenceTransformer model to use\n",
    "model_name = 'sentence-transformers/distiluse-base-multilingual-cased-v2'\n",
    "\n",
    "# Create an instance of the class\n",
    "Model_instance = Model(sentences, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.7s aprox.\n",
    "# Calculate and display similarity between the texts\n",
    "Model_instance.calculate_similarity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
