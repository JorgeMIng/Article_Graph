{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will document step by step different approaches to group documents in different topics using the **topic modeling** strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What exactly is Topic Modeling?\n",
    "\n",
    "**Topic Modeling** is a technique used to discover the **distribution of uderlying topics** in a collection of documents.\n",
    "\n",
    "Each topic is a collection of co-occuring words in a set of documents. The order of the words is not taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two different Topic Modeling algorithms\n",
    "\n",
    "We will test 2 different algorithms with this set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of texts simulating documents' abstracts\n",
    "\n",
    "docs = [\n",
    "    'The universe is a vast expanse of space containing countless galaxies, stars, planets, and other celestial objects.',\n",
    "    'Ancient civilizations such as the Egyptians, Greeks, and Romans have left behind rich legacies of art, architecture, and knowledge.',\n",
    "    'Climate change is a pressing global issue that requires urgent action to mitigate its impacts on the environment and human societies.',\n",
    "    'The rise of artificial intelligence has led to both excitement and concern about its potential to revolutionize industries and transform society.',\n",
    "    'Renewable energy sources like solar and wind power are increasingly being adopted as alternatives to fossil fuels to combat climate change.',\n",
    "    'The human brain is a complex organ responsible for controlling thoughts, emotions, movements, and bodily functions.',\n",
    "    'Cultural diversity enriches societies by fostering tolerance, understanding, and appreciation of different traditions, languages, and perspectives.',\n",
    "    'Globalization has connected people, cultures, and economies around the world, leading to both opportunities and challenges.',\n",
    "    'The history of mathematics spans thousands of years and includes the development of algebra, geometry, calculus, and other branches.',\n",
    "    'Artificial neural networks are computational models inspired by the structure and function of biological neural networks, used in various applications like image recognition and natural language processing.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make available the packages inside the topic_modeling folder\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirchlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is the most popular given its speed. It calculates probability distributions and uses bag-of-words.\n",
    "\n",
    "Let's try to test **LDA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topic_modeling.lda import LDA\n",
    "\n",
    "# Create a LDA specifying the number of topics and the number of words to include in each topic\n",
    "# By default:\n",
    "# - num_topics= 3\n",
    "# - num_words = 5\n",
    "lda_model = LDA(corpus=docs, num_topics=3, num_words=7)\n",
    "\n",
    "# Fit the model to the documents\n",
    "lda_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Generated 3 topics:\n",
      "> Topic 0: ['and', 'of', 'the', 'networks', 'neural', 'are', 'like']\n",
      "> Topic 1: ['and', 'to', 'the', 'its', 'has', 'both', 'human']\n",
      "> Topic 2: ['of', 'the', 'and', 'other', 'is', 'years', 'mathematics']\n"
     ]
    }
   ],
   "source": [
    "# Print the generated topics\n",
    "print(f'\\n> Generated {len(lda_model.topics)} topics:')\n",
    "for i, topic in enumerate(lda_model.topics):\n",
    "    print(f'> Topic {i}: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Topic distribution for the new document:\n",
      "> Document: The universe is a vast expanse of space containing countless galaxies, stars, planets, and other celestial objects.\n",
      "> Topic 0: 0.02021521411040529\n",
      "> Topic 1: 0.02024417640495833\n",
      "> Topic 2: 0.9595406094846364\n"
     ]
    }
   ],
   "source": [
    "# Obtain the topic distributions for one of the documents\n",
    "document = 'The universe is a vast expanse of space containing countless galaxies, stars, planets, and other celestial objects.'\n",
    "topic_dists = lda_model.predict(document)\n",
    "\n",
    "# Print the topic distributions for the new document\n",
    "print('\\n> Topic distribution for the new document:')\n",
    "print(f'> Document: {document}')\n",
    "for topic_id, topic_dist in topic_dists.items():\n",
    "    print(f'> Topic {topic_id}: {topic_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Topic distributions for all the documents:\n",
      "Document 0:\n",
      "> Topic 0: 0.02021521411040529\n",
      "> Topic 1: 0.02024417640495833\n",
      "> Topic 2: 0.9595406094846364\n",
      "Document 1:\n",
      "> Topic 0: 0.9651299780630253\n",
      "> Topic 1: 0.017259433214297872\n",
      "> Topic 2: 0.01761058872267682\n",
      "Document 2:\n",
      "> Topic 0: 0.016634160075727888\n",
      "> Topic 1: 0.9669948380257228\n",
      "> Topic 2: 0.016371001898549366\n",
      "Document 3:\n",
      "> Topic 0: 0.015962670482873444\n",
      "> Topic 1: 0.9677665923062956\n",
      "> Topic 2: 0.016270737210831044\n",
      "Document 4:\n",
      "> Topic 0: 0.9681498629664033\n",
      "> Topic 1: 0.016479939543712442\n",
      "> Topic 2: 0.015370197489884448\n",
      "Document 5:\n",
      "> Topic 0: 0.9558515695568268\n",
      "> Topic 1: 0.02215066814274007\n",
      "> Topic 2: 0.021997762300433023\n",
      "Document 6:\n",
      "> Topic 0: 0.9590652900476302\n",
      "> Topic 1: 0.020416506994999164\n",
      "> Topic 2: 0.020518202957370658\n",
      "Document 7:\n",
      "> Topic 0: 0.020292260017164655\n",
      "> Topic 1: 0.9594720442513912\n",
      "> Topic 2: 0.020235695731444136\n",
      "Document 8:\n",
      "> Topic 0: 0.01744352667461845\n",
      "> Topic 1: 0.01735656884372757\n",
      "> Topic 2: 0.965199904481654\n",
      "Document 9:\n",
      "> Topic 0: 0.9753064827991356\n",
      "> Topic 1: 0.012309417751643037\n",
      "> Topic 2: 0.012384099449221518\n"
     ]
    }
   ],
   "source": [
    "# Obtain the topic distributions for every document onside the corpus\n",
    "lda_model.predict_all()\n",
    "\n",
    "# Print the topic distributions for all the documents\n",
    "print('\\n> Topic distributions for all the documents:')\n",
    "for doc_id, doc_info in enumerate(lda_model.topic_distributions):\n",
    "    print(f'Document {doc_id}:')\n",
    "    for topic_id, topic_dist in doc_info.items():\n",
    "        print(f'> Topic {topic_id}: {topic_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Coherence of the model: -0.5566220959928455\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence of the model\n",
    "lda_model.calculate_coherence()\n",
    "print(f'> Coherence of the model: {lda_model.coherence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is based on **B**idirectional **E**ncoder **R**epresentations from **T**ransformers (BERT).\n",
    "\n",
    "It is able to also capture the context of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
