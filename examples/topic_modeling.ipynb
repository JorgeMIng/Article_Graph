{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will document step by step different approaches to group documents in different topics using the **topic modeling** strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What exactly is Topic Modeling?\n",
    "\n",
    "**Topic Modeling** is a technique used to discover the **distribution of uderlying topics** in a collection of documents.\n",
    "\n",
    "Each topic is a collection of co-occuring words in a set of documents. The order of the words is not taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two different Topic Modeling algorithms\n",
    "\n",
    "We will test 2 different algorithms with this set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of texts simulating documents' abstracts\n",
    "\n",
    "docs = [\n",
    "    'The universe is a vast expanse of space containing countless galaxies, stars, planets, and other celestial objects.',\n",
    "    'Ancient civilizations such as the Egyptians, Greeks, and Romans have left behind rich legacies of art, architecture, and knowledge.',\n",
    "    'Climate change is a pressing global issue that requires urgent action to mitigate its impacts on the environment and human societies.',\n",
    "    'The rise of artificial intelligence has led to both excitement and concern about its potential to revolutionize industries and transform society.',\n",
    "    'Renewable energy sources like solar and wind power are increasingly being adopted as alternatives to fossil fuels to combat climate change.',\n",
    "    'The human brain is a complex organ responsible for controlling thoughts, emotions, movements, and bodily functions.',\n",
    "    'Cultural diversity enriches societies by fostering tolerance, understanding, and appreciation of different traditions, languages, and perspectives.',\n",
    "    'Globalization has connected people, cultures, and economies around the world, leading to both opportunities and challenges.',\n",
    "    'The history of mathematics spans thousands of years and includes the development of algebra, geometry, calculus, and other branches.',\n",
    "    'Artificial neural networks are computational models inspired by the structure and function of biological neural networks, used in various applications like image recognition and natural language processing.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirchlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is the most popular given its speed. It calculates probability distributions and uses bag-of-words.\n",
    "\n",
    "Let's try to test **LDA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "class LDATopicModel:\n",
    "    \"\"\"\n",
    "    A class to apply Latent Dirichlet Allocation (LDA) to a corpus of documents and extract topics.\n",
    "    \"\"\"\n",
    "    def __init__(self, corpus: list[str], num_topics: int=5):\n",
    "        \"\"\"\n",
    "        Initialize the LDA topic model with the given corpus of documents and number of topics.\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        self.num_topics = num_topics\n",
    "        self.vectorizer: CountVectorizer = None\n",
    "        self.model: LatentDirichletAllocation = None\n",
    "        self.topics: list[list[str]] = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit the LDA model to the corpus of documents and extract the top words for each topic.\n",
    "        \"\"\"\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        X = self.vectorizer.fit_transform(self.corpus)\n",
    "\n",
    "        self.model = LatentDirichletAllocation(n_components=self.num_topics, random_state=0)\n",
    "        self.model.fit(X)\n",
    "\n",
    "        self.topics = self.__get_topics()\n",
    "\n",
    "    def predict(self, doc: str):\n",
    "        \"\"\"\n",
    "        Predict the topic distribution for a new document.\n",
    "        \"\"\"\n",
    "        X = self.vectorizer.transform([doc])\n",
    "        return self.model.transform(X)[0]\n",
    "    \n",
    "    def __get_topics(self, n_words=5):\n",
    "        \"\"\"\n",
    "        Get the top words for each topic in the LDA model.\n",
    "        \"\"\"\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        topics = []\n",
    "        for topic in self.model.components_:\n",
    "            topics.append([feature_names[i] for i in topic.argsort()[:-n_words-1:-1]])\n",
    "        return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the LDATopicModel class and fit it to the corpus of documents\n",
    "lda_model = LDATopicModel(docs, num_topics=3)\n",
    "lda_model.fit()\n",
    "\n",
    "# Print the generated topics\n",
    "print(f'> Generated {len(lda_model.topics)} topics:')\n",
    "for i, topic in enumerate(lda_model.topics):\n",
    "    print(f'> Topic {i}: {topic}')\n",
    "\n",
    "# Predict the topic distribution for a new document\n",
    "lda_model.predict('The universe is a vast expanse of space containing countless galaxies, stars, planets, and other celestial objects.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate all the topics\n",
    "def generate_topics(count_vec: CountVectorizer, lda: LatentDirichletAllocation) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Generate and return a list of topics given an already trained CountVectorizer and a LDA.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    feature_names = count_vec.get_feature_names_out()\n",
    "    for topic in lda.components_:\n",
    "        result.append([feature_names[i] for i in topic.argsort()[:-5:-1]])\n",
    "    return result\n",
    "\n",
    "# Generate the topics\n",
    "generate_topics(count_vec, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that calculates the probability of a text to belong to each topic\n",
    "def calculate_probablities_for_each_topic(\n",
    "        text: str,\n",
    "        count_vec: CountVectorizer,\n",
    "        lda: LatentDirichletAllocation) -> list[float]:\n",
    "    \"\"\"\n",
    "    Calculate the probability of a text to belong to each topic.\n",
    "    \"\"\"\n",
    "    bag_of_words = count_vec.transform([text])\n",
    "    topic_dist = lda.transform(bag_of_words)\n",
    "    return [p for p in topic_dist[0]]\n",
    "\n",
    "# Calculate the probability of a text to belong to each topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is based on **Bidirectional Encoder Representations from Transformers** (**BERT**).\n",
    "\n",
    "It is able to also capture the context of words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
